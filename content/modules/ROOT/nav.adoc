* 1. Background
** xref:01-01-setting-stage.adoc[1.1 What are LLMs?]
** xref:01-02-current-process.adoc[1.2 What are Neural Networks?]
** xref:01-03-proposed-improvements.adoc[1.3 OpenShift AI]
** xref:01-04-examples-from-prototype.adoc[1.4 Neural Magic Model Optimization]

* 2. Connection and Setup ({user})
** xref:02-01-getting-connected.adoc[2.1 Getting connected]
** xref:02-02-creating-project.adoc[2.2 Creating your project and pipeline server]
** xref:02-03-creating-workbench.adoc[2.3 Creating your workbench]
** xref:02-03-creating-workbench.adoc[2.4 Creating your pipeline]

* 3. Workbench: Working with LLM Compressor
** xref:03-01-int-4-quantization.adoc[3.1 Weights Only Quantization (INT-4)]
** xref:03-02-int-8-quantization.adoc[3.2 Weights and Activation Quantization (INT-8)]
** xref:03-03-fp-8-quantization.adoc[3.3 Weights and Activation Quantization (FP-8)]

* 4. Pipelines: Working with LLM Compressor
** xref:04-01-quantization-pipeline.adoc[4.1 Quantization with Pipelines]
** xref:04-02-quantization-pipeline-exercise.adoc[4.2 Exercise]

* 5. Model Performance ComparisonImage Processing
** xref:05-01-base-model.adoc[5.1 Serving Base Models]
** xref:05-02-optimized-model.adoc[5.2 Serving Optimized Models]

* 6. End of Lab
** xref:06-01-end-of-lab.adoc[6.1 Thanks]
